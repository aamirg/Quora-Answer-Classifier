{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# [Quora Answer Classifier](https://www.quora.com/challenges#answer_classifier) \n",
    "\n",
    "Created on Wed Aug 10 12:35:52 2016\n",
    "@author: Aamir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "670fa303-9817-4c28-b8ee-352ba76e749d"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read input data from local disk and separate the training & testing data. We also separate the training labels at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, train_label, test = [], [], []\n",
    "\n",
    "with open(\"input00.txt\", \"r\") as input_file:\n",
    "    data = input_file.readlines()\n",
    "    \n",
    "train_count = int(data[0].split()[0])\n",
    "test_count = int(data[train_count+1])\n",
    "\n",
    "for indx in xrange(1, train_count+1):\n",
    "    temp = data[indx].split()\n",
    "    train_label.append(int(temp[1]))\n",
    "    train.append([float(val.split(\":\")[1]) for val in temp[2:]])\n",
    "\n",
    "for indx in xrange(train_count+2, train_count+test_count+2):\n",
    "    temp = data[indx].split()\n",
    "    test.append([float(val.split(\":\")[1]) for val in temp[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print \"Training data - \", train[:5]\n",
    "#print \"Training labels - \", train_label[:5]\n",
    "#print \"Testing data - \", test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"output00.txt\",\"r\") as output_file:\n",
    "    output_data = output_file.readlines()\n",
    "test_labels = [int(row.split()[1]) for row in output_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data format looks fine, we use feature scaling for better performance while training our classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "train_scaled, test_scaled = preprocessing.scale(np.asarray(train)), preprocessing.scale(np.asarray(test))\n",
    "#print \"Training data - \", train_scaled[:5]\n",
    "#print \"Testing data - \", test_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F-1: 0.82 (+/- 0.03)\n",
      "\n",
      "Classification report - \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.82      0.79      0.81       250\n",
      "          1       0.80      0.83      0.81       250\n",
      "\n",
      "avg / total       0.81      0.81      0.81       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(C=0.8, kernel='linear', decision_function_shape=\"ovo\")\n",
    "scores = cross_validation.cross_val_score(svc, train_scaled, train_label, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation F-1: {} (+/- {})\".format(round(scores.mean(),2), round(scores.std() * 2,2)))\n",
    "svc.fit(train_scaled, train_label)\n",
    "predict_labels = svc.predict(test_scaled)\n",
    "print \"\\nClassification report - \\n\", classification_report(test_labels, predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hackerrank Score for SVM - 0.0 as it didn't pass both test cases. For test case 1 it results in time out error, probably due to a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tr Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F-1: 0.82 (+/- 0.02)\n",
      "\n",
      "Classification report - \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.81      0.81       250\n",
      "          1       0.81      0.82      0.81       250\n",
      "\n",
      "avg / total       0.81      0.81      0.81       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(C=1, penalty='l2', solver='liblinear')\n",
    "logistic.fit(train_scaled, train_label)\n",
    "scores = cross_validation.cross_val_score(logistic, train_scaled, train_label, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation F-1: {} (+/- {})\".format(round(scores.mean(),2), round(scores.std() * 2,2)))\n",
    "predict_labels = logistic.predict(test_scaled)\n",
    "print \"\\nClassification report - \\n\", classification_report(test_labels, predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hackerrank Score obtained for Logistic regression - 83.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F-1: 0.85 (+/- 0.03)\n",
      "\n",
      "Classification report - \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.83      0.80      0.82       250\n",
      "          1       0.81      0.84      0.82       250\n",
      "\n",
      "avg / total       0.82      0.82      0.82       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RFC(n_estimators=15, verbose=0, criterion='gini', min_samples_split=15, min_samples_leaf=7, max_features='log2')\n",
    "scores = cross_validation.cross_val_score(rfc, train_scaled, train_label, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation F-1: {} (+/- {})\".format(round(scores.mean(),2), round(scores.std() * 2,2)))\n",
    "rfc.fit(train_scaled, train_label)\n",
    "predict_labels = rfc.predict(test_scaled)\n",
    "print \"\\nClassification report - \\n\", classification_report(test_labels, predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hackerrank Score for Random Forest - 86.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F-1: 0.85 (+/- 0.03)\n",
      "\n",
      "Classification report - \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.82      0.84      0.83       250\n",
      "          1       0.84      0.82      0.83       250\n",
      "\n",
      "avg / total       0.83      0.83      0.83       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aboost = AdaBoostClassifier(base_estimator=rfc, n_estimators=5, learning_rate=0.5, algorithm='SAMME.R', random_state=True)\n",
    "scores = cross_validation.cross_val_score(aboost, train_scaled, train_label, cv=10, scoring='f1_weighted')\n",
    "print(\"Cross Validation F-1: {} (+/- {})\".format(round(scores.mean(),2), round(scores.std() * 2,2)))\n",
    "aboost.fit(train, train_label)\n",
    "predict_labels = aboost.predict(test)\n",
    "print \"\\nClassification report - \\n\", classification_report(test_labels, predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hackerrank score for Adaboost Classifier - 87.38"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "1b3b1ec1-c643-426f-bf76-c79eb1c53db5": {
     "id": "1b3b1ec1-c643-426f-bf76-c79eb1c53db5",
     "prev": "e4fa752d-38d6-4c53-b16f-30369fae9afd",
     "regions": {
      "901842bb-479a-4369-be91-d76ace44de41": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "670fa303-9817-4c28-b8ee-352ba76e749d",
        "part": "whole"
       },
       "id": "901842bb-479a-4369-be91-d76ace44de41"
      }
     }
    },
    "e4fa752d-38d6-4c53-b16f-30369fae9afd": {
     "id": "e4fa752d-38d6-4c53-b16f-30369fae9afd",
     "prev": null,
     "regions": {
      "8b76a4c8-babb-43c7-936c-f97c3583b921": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "86d1eb67-6e7c-4e8d-861c-d7606c147711",
        "part": "whole"
       },
       "id": "8b76a4c8-babb-43c7-936c-f97c3583b921"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
